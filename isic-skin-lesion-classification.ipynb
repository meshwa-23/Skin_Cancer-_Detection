{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-14T16:53:20.618664Z",
     "iopub.status.busy": "2024-06-14T16:53:20.618389Z",
     "iopub.status.idle": "2024-06-14T17:48:01.186270Z",
     "shell.execute_reply": "2024-06-14T17:48:01.185303Z",
     "shell.execute_reply.started": "2024-06-14T16:53:20.618640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Load data from CSV\n",
    "csv_path = '/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Exclude 'UNK' class from the classes list and class to index mapping\n",
    "classes = data.columns[1:-1].tolist()\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "# Extract image names and labels\n",
    "image_names = data['image'].tolist()\n",
    "labels = data.drop(columns=['image', 'UNK']).values.tolist()\n",
    "\n",
    "# Construct full paths to images\n",
    "image_dir = '/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input'\n",
    "image_paths = [os.path.join(image_dir, name + '.jpg') for name in image_names]\n",
    "\n",
    "# Visualize the distribution of classes\n",
    "class_counts = np.sum(labels, axis=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=classes, y=class_counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Split data into training and test sets and convert labels\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing functions\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [260, 260])  # Resize without 'nearest' mode\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
    "    return image\n",
    "\n",
    "def data_augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label\n",
    "\n",
    "def load_and_preprocess_from_path_labels(path, label):\n",
    "    return load_and_preprocess_image(path), label\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.map(load_and_preprocess_from_path_labels, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                   .map(data_augment, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                   .shuffle(2048).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(load_and_preprocess_from_path_labels, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Define learning rate schedule\n",
    "LR_START = 0.00001\n",
    "LR_MAX = 0.00005 \n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 4\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = 0.8\n",
    "EPOCHS = 15\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "# Load EfficientNetB2 model and add custom classification layer\n",
    "base_model = tf.keras.applications.EfficientNetB2(include_top=False, input_shape=(260, 260, 3), pooling='avg')\n",
    "base_output = base_model.output\n",
    "classifier = tf.keras.layers.Dense(len(classes), activation='softmax')(base_output)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=classifier)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_callback],\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('/kaggle/working/EfficientNetB2.h5')\n",
    "\n",
    "# Evaluate model performance\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred = np.argmax(model.predict(test_ds), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print the number of images belonging to each label in training data\n",
    "print(\"Training Class Distribution:\")\n",
    "print(data.drop(columns=['image', 'UNK']).sum())\n",
    "\n",
    "# Print the number of images belonging to each label in test data\n",
    "print(\"Test Class Distribution:\")\n",
    "test_data = pd.DataFrame({'image': test_images, 'label': test_labels})\n",
    "print(test_data['label'].value_counts())\n",
    "\n",
    "# Class index to name mapping\n",
    "class_index_to_name = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "print(\"Class Index to Name Mapping:\")\n",
    "print(class_index_to_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T17:48:01.189239Z",
     "iopub.status.busy": "2024-06-14T17:48:01.188729Z",
     "iopub.status.idle": "2024-06-14T17:48:17.262730Z",
     "shell.execute_reply": "2024-06-14T17:48:17.261834Z",
     "shell.execute_reply.started": "2024-06-14T17:48:01.189206Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluate model performance\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred = np.argmax(model.predict(test_ds), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, classes)\n",
    "\n",
    "# Print the number of images belonging to each label in training data\n",
    "print(\"Training Class Distribution:\")\n",
    "print(data.drop(columns=['image', 'UNK']).sum())\n",
    "\n",
    "# Print the number of images belonging to each label in test data\n",
    "print(\"Test Class Distribution:\")\n",
    "test_data = pd.DataFrame({'image': test_images, 'label': test_labels})\n",
    "print(test_data['label'].value_counts())\n",
    "\n",
    "# Class index to name mapping\n",
    "class_index_to_name = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "print(\"Class Index to Name Mapping:\")\n",
    "print(class_index_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T17:48:17.264061Z",
     "iopub.status.busy": "2024-06-14T17:48:17.263787Z",
     "iopub.status.idle": "2024-06-14T17:48:28.903098Z",
     "shell.execute_reply": "2024-06-14T17:48:28.902102Z",
     "shell.execute_reply.started": "2024-06-14T17:48:17.264037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [260, 260])\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Function to predict the label of a single image\n",
    "def predict_image(model, image_path, class_index_to_name):\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(image)\n",
    "    predicted_label_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_label_name = class_index_to_name[predicted_label_index]\n",
    "    return predicted_label_name\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/kaggle/working/EfficientNetB2.h5')\n",
    "\n",
    "# Dictionary to map class indices to label names\n",
    "class_index_to_name = {0: 'MEL', 1: 'NV', 2: 'BCC', 3: 'AK', 4: 'BKL', 5: 'DF', 6: 'VASC', 7: 'SCC'}\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = '/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input/ISIC_0012214_downsampled.jpg'\n",
    "\n",
    "# Predict the label of the image\n",
    "predicted_label = predict_image(model, image_path, class_index_to_name)\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T17:48:28.905002Z",
     "iopub.status.busy": "2024-06-14T17:48:28.904636Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [260, 260])\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Function to predict the label of a single image\n",
    "def predict_image(model, image_path):\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(image)\n",
    "    predicted_label = tf.argmax(predictions, axis=1)[0]\n",
    "    return predicted_label.numpy()\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/kaggle/working/EfficientNetB2.h5')\n",
    "\n",
    "# Load the CSV file with image names\n",
    "csv_path = '/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Path to the directory containing images\n",
    "image_dir = '/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input'\n",
    "\n",
    "# Predict labels for all rows and create a new column for predicted labels\n",
    "predicted_labels = []\n",
    "for index, row in data.iterrows():\n",
    "    image_name = row['image']\n",
    "    image_path = os.path.join(image_dir, image_name + '.jpg')\n",
    "    predicted_label = predict_image(model, image_path)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Add predicted labels to the DataFrame\n",
    "data['predicted_label'] = predicted_labels\n",
    "\n",
    "# Save the updated CSV file with predicted labels for all rows\n",
    "output_csv_path = '/kaggle/working/predicted_labels.csv'\n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Predicted labels saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T18:21:49.838152Z",
     "iopub.status.busy": "2024-06-14T18:21:49.837792Z",
     "iopub.status.idle": "2024-06-14T18:21:51.356704Z",
     "shell.execute_reply": "2024-06-14T18:21:51.355766Z",
     "shell.execute_reply.started": "2024-06-14T18:21:49.838126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = '/kaggle/working/predicted_labels.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Define the mapping\n",
    "mapping = {0: 'MEL', 1: 'NV', 2: 'BCC', 3: 'AK', 4: 'BKL', 5: 'DF', 6: 'VASC', 7: 'SCC'}\n",
    "\n",
    "# Check the authenticity of the predictions for all rows\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    predicted_label_index = row['predicted_label']\n",
    "    predicted_label_name = mapping[predicted_label_index]\n",
    "    \n",
    "    # Check if the predicted label matches the actual label\n",
    "    if row[predicted_label_name] == 1:\n",
    "        correct_predictions += 1\n",
    "    else:\n",
    "        incorrect_predictions += 1\n",
    "\n",
    "# Output the results\n",
    "total_predictions = len(df)\n",
    "\n",
    "print(f'Correct predictions: {correct_predictions}')\n",
    "print(f'Incorrect predictions: {incorrect_predictions}')\n",
    "\n",
    "# Calculate percentages\n",
    "correct_percentage = (correct_predictions / total_predictions) * 100\n",
    "incorrect_percentage = (incorrect_predictions / total_predictions) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f'Correct prediction percentage: {correct_percentage:.2f}%')\n",
    "print(f'Incorrect prediction percentage: {incorrect_percentage:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 679322,
     "sourceId": 1193409,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
